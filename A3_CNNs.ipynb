{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from typing import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## About the dataset\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "The classes are:\n",
    "\n",
    "| Label |\tDescription |\n",
    "|-------|-------------|\n",
    "| 0     |\tairplane    |\n",
    "| 1     |\tautomobile  |\n",
    "| 2     |\tbird        |\n",
    "| 3     |\tcat         |\n",
    "| 4     |\tdeer        |\n",
    "| 5     |\tdog         |\n",
    "| 6     |\tfrog        |\n",
    "| 7     |\thorse       |\n",
    "| 8     |\tship        |\n",
    "| 9     |\ttruck       |\n",
    "\n",
    "This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
    "Here is the list of classes in the CIFAR-100:\n",
    "\n",
    "| Superclass |\tClasses |\n",
    "|------------|----------|\n",
    "|aquatic mammals|\tbeaver, dolphin, otter, seal, whale|\n",
    "|fish|\taquarium fish, flatfish, ray, shark, trout|\n",
    "|flowers|\torchids, poppies, roses, sunflowers, tulips|\n",
    "|food containers|\tbottles, bowls, cans, cups, plates|\n",
    "|fruit and vegetables|\tapples, mushrooms, oranges, pears, sweet peppers|\n",
    "|household electrical devices|\tclock, computer keyboard, lamp, telephone, television|\n",
    "|household furniture|\tbed, chair, couch, table, wardrobe|\n",
    "|insects|\tbee, beetle, butterfly, caterpillar, cockroach|\n",
    "|large carnivores|\tbear, leopard, lion, tiger, wolf|\n",
    "|large man-made outdoor things|\tbridge, castle, house, road, skyscraper|\n",
    "|large natural outdoor scenes|\tcloud, forest, mountain, plain, sea|\n",
    "|large omnivores and herbivores|\tcamel, cattle, chimpanzee, elephant, kangaroo|\n",
    "|medium-sized mammals|\tfox, porcupine, possum, raccoon, skunk|\n",
    "|non-insect invertebrates|\tcrab, lobster, snail, spider, worm|\n",
    "|people|\tbaby, boy, girl, man, woman|\n",
    "|reptiles|\tcrocodile, dinosaur, lizard, snake, turtle|\n",
    "|small mammals|\thamster, mouse, rabbit, shrew, squirrel|\n",
    "|trees|\tmaple, oak, palm, pine, willow|\n",
    "|vehicles 1|\tbicycle, bus, motorcycle, pickup truck, train|\n",
    "|vehicles 2|\tlawn-mower, rocket, streetcar, tank, tractor|\n",
    "\n",
    "\n",
    "Source: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train size: 50000\n",
      "Test size: 10000\n",
      "Image shape: torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "\n",
    "target_transform = transforms.Lambda(lambda x: torch.nn.functional.one_hot(torch.tensor(x).long(), num_classes=10).float())\n",
    "\n",
    "train = datasets.CIFAR10(\n",
    "    \"cifar10\",\n",
    "    train=True,\n",
    "    transform=train_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test  = datasets.CIFAR10(\"cifar10\",\n",
    "    train=False,\n",
    "    transform=test_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=128,  shuffle=True)\n",
    "testloader  = torch.utils.data.DataLoader(test,  batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train)}\")\n",
    "print(f\"Test size: {len(test)}\")\n",
    "\n",
    "print(f\"Image shape: {train[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  (9): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (10): ReLU()\n",
      "  (11): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "--------------------  Training  --------------------\n",
      "Epoch: 1\n",
      "Train loss: 1.8530, accuracy: 0.3183\n",
      "Test loss: 1.5967, accuracy: 0.4278\n",
      "--------------------------------------------------\n",
      "Epoch: 2\n",
      "Train loss: 1.6923, accuracy: 0.3794\n",
      "Test loss: 1.5454, accuracy: 0.4623\n",
      "--------------------------------------------------\n",
      "Epoch: 3\n",
      "Train loss: 1.6140, accuracy: 0.4137\n",
      "Test loss: 1.4174, accuracy: 0.4966\n",
      "--------------------------------------------------\n",
      "Epoch: 4\n",
      "Train loss: 1.5559, accuracy: 0.4361\n",
      "Test loss: 1.4260, accuracy: 0.5008\n",
      "--------------------------------------------------\n",
      "Epoch: 5\n",
      "Train loss: 1.5171, accuracy: 0.4498\n",
      "Test loss: 1.3648, accuracy: 0.5212\n",
      "--------------------------------------------------\n",
      "Epoch: 6\n",
      "Train loss: 1.4818, accuracy: 0.4646\n",
      "Test loss: 1.3318, accuracy: 0.5305\n",
      "--------------------------------------------------\n",
      "Epoch: 7\n",
      "Train loss: 1.4598, accuracy: 0.4742\n",
      "Test loss: 1.3310, accuracy: 0.5297\n",
      "--------------------------------------------------\n",
      "Epoch: 8\n",
      "Train loss: 1.4443, accuracy: 0.4816\n",
      "Test loss: 1.3406, accuracy: 0.5338\n",
      "--------------------------------------------------\n",
      "Epoch: 9\n",
      "Train loss: 1.4140, accuracy: 0.4887\n",
      "Test loss: 1.3051, accuracy: 0.5491\n",
      "--------------------------------------------------\n",
      "Epoch: 10\n",
      "Train loss: 1.3992, accuracy: 0.4971\n",
      "Test loss: 1.2556, accuracy: 0.5629\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 32, 3, 1, 1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Conv2d(32, 64, 3, 1, 1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(4096, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 10),\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(\"-\" * 20, \" Training \", \"-\" * 20)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc  = 0\n",
    "    for batch, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "    train_loss /= batch + 1\n",
    "    train_acc  /= trainloader.batch_size * (batch + 1)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        accuracy  = 0\n",
    "        for batch, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            y_pred = model(images)\n",
    "            loss = criterion(y_pred, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            accuracy  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "        test_loss /= batch + 1\n",
    "        accuracy  /= testloader.batch_size * (batch + 1)\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}, accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([50000, 32, 32, 3])\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test  = x_test / 255\n",
    "\n",
    "augment = keras.Sequential([\n",
    "    keras.layers.RandomRotation(0.2),\n",
    "    keras.layers.RandomZoom(0.2),\n",
    "    keras.layers.RandomFlip(),\n",
    "])\n",
    "\n",
    "x_train = augment(x_train)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  Training  --------------------\n",
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - loss: 2.3144 - sparse_categorical_accuracy: 0.2649 - val_loss: 1.6728 - val_sparse_categorical_accuracy: 0.3954\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 1.7051 - sparse_categorical_accuracy: 0.3862 - val_loss: 1.4701 - val_sparse_categorical_accuracy: 0.4670\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.5920 - sparse_categorical_accuracy: 0.4320 - val_loss: 1.5970 - val_sparse_categorical_accuracy: 0.4378\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - loss: 1.4921 - sparse_categorical_accuracy: 0.4666 - val_loss: 1.4970 - val_sparse_categorical_accuracy: 0.4639\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - loss: 1.4281 - sparse_categorical_accuracy: 0.4927 - val_loss: 1.3773 - val_sparse_categorical_accuracy: 0.5013\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - loss: 1.3535 - sparse_categorical_accuracy: 0.5161 - val_loss: 1.9272 - val_sparse_categorical_accuracy: 0.3959\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - loss: 1.2933 - sparse_categorical_accuracy: 0.5426 - val_loss: 1.3795 - val_sparse_categorical_accuracy: 0.5186\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 14ms/step - loss: 1.2177 - sparse_categorical_accuracy: 0.5683 - val_loss: 1.4478 - val_sparse_categorical_accuracy: 0.5074\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 1.1463 - sparse_categorical_accuracy: 0.5940 - val_loss: 1.5522 - val_sparse_categorical_accuracy: 0.4896\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - loss: 1.0942 - sparse_categorical_accuracy: 0.6139 - val_loss: 1.4432 - val_sparse_categorical_accuracy: 0.5200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f6fa8a7ee10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "print(\"-\" * 20, \" Training \", \"-\" * 20)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy()\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 Transfet Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train size: 50000\n",
      "Test size: 10000\n",
      "Image shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "\n",
    "target_transform = transforms.Lambda(lambda x: torch.nn.functional.one_hot(torch.tensor(x).long(), num_classes=10).float())\n",
    "\n",
    "train = datasets.CIFAR10(\n",
    "    \"cifar10\",\n",
    "    train=True,\n",
    "    transform=train_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test  = datasets.CIFAR10(\"cifar10\",\n",
    "    train=False,\n",
    "    transform=test_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=128,  shuffle=True)\n",
    "testloader  = torch.utils.data.DataLoader(test,  batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train)}\")\n",
    "print(f\"Test size: {len(test)}\")\n",
    "\n",
    "print(f\"Image shape: {train[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  ResNet50  --------------------\n",
      "--------------------  Training  --------------------\n",
      "Epoch: 1\n",
      "Train loss: 2.0252, accuracy: 0.2930\n",
      "Test loss: 1.7218, accuracy: 0.4437\n",
      "--------------------------------------------------\n",
      "Epoch: 2\n",
      "Train loss: 1.5836, accuracy: 0.4903\n",
      "Test loss: 1.4162, accuracy: 0.5484\n",
      "--------------------------------------------------\n",
      "Epoch: 3\n",
      "Train loss: 1.4025, accuracy: 0.5427\n",
      "Test loss: 1.2732, accuracy: 0.5777\n",
      "--------------------------------------------------\n",
      "Epoch: 4\n",
      "Train loss: 1.3088, accuracy: 0.5668\n",
      "Test loss: 1.1808, accuracy: 0.6057\n",
      "--------------------------------------------------\n",
      "Epoch: 5\n",
      "Train loss: 1.2502, accuracy: 0.5803\n",
      "Test loss: 1.1209, accuracy: 0.6211\n",
      "--------------------------------------------------\n",
      "Epoch: 6\n",
      "Train loss: 1.2150, accuracy: 0.5890\n",
      "Test loss: 1.0621, accuracy: 0.6480\n",
      "--------------------------------------------------\n",
      "Epoch: 7\n",
      "Train loss: 1.1835, accuracy: 0.5991\n",
      "Test loss: 1.0571, accuracy: 0.6439\n",
      "--------------------------------------------------\n",
      "Epoch: 8\n",
      "Train loss: 1.1638, accuracy: 0.6001\n",
      "Test loss: 1.0233, accuracy: 0.6551\n",
      "--------------------------------------------------\n",
      "Epoch: 9\n",
      "Train loss: 1.1424, accuracy: 0.6069\n",
      "Test loss: 1.0007, accuracy: 0.6612\n",
      "--------------------------------------------------\n",
      "Epoch: 10\n",
      "Train loss: 1.1341, accuracy: 0.6097\n",
      "Test loss: 0.9815, accuracy: 0.6665\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"-\" * 20, \" ResNet50 \", \"-\" * 20)\n",
    "print(\"-\" * 20, \" Training \", \"-\" * 20)\n",
    "\n",
    "resnet.fc = torch.nn.Linear(512, 10)\n",
    "\n",
    "resnet.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet.fc.parameters(), lr=0.0001, betas=(0.9, 0.9))\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    resnet.train()\n",
    "    train_loss = 0\n",
    "    train_acc  = 0\n",
    "    for batch, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        y_pred = resnet(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "    train_loss /= batch + 1\n",
    "    train_acc  /= trainloader.batch_size * (batch + 1)\n",
    "\n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        accuracy  = 0\n",
    "        for batch, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            y_pred = resnet(images)\n",
    "            loss = criterion(y_pred, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            accuracy  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "        test_loss /= batch + 1\n",
    "        accuracy  /= testloader.batch_size * (batch + 1)\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}, accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to cifar100/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169M/169M [00:49<00:00, 3.42MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting cifar100/cifar-100-python.tar.gz to cifar100\n",
      "Files already downloaded and verified\n",
      "Train size: 50000\n",
      "Test size: 10000\n",
      "Image shape: torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomResizedCrop(32),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "\n",
    "target_transform = transforms.Lambda(lambda x: torch.nn.functional.one_hot(torch.tensor(x).long(), num_classes=100).float())\n",
    "\n",
    "train = datasets.CIFAR100(\n",
    "    \"cifar100\",\n",
    "    train=True,\n",
    "    transform=train_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test  = datasets.CIFAR100(\n",
    "    \"cifar100\",\n",
    "    train=False,\n",
    "    transform=test_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=128,  shuffle=True)\n",
    "testloader  = torch.utils.data.DataLoader(test,  batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train)}\")\n",
    "print(f\"Test size: {len(test)}\")\n",
    "\n",
    "print(f\"Image shape: {train[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): ReLU()\n",
      "  (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (8): Flatten(start_dim=1, end_dim=-1)\n",
      "  (9): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "  (10): ReLU()\n",
      "  (11): Linear(in_features=1024, out_features=100, bias=True)\n",
      ")\n",
      "--------------------  Training  --------------------\n",
      "Epoch: 1\n",
      "Train loss: 4.0312, accuracy: 0.0872\n",
      "Test loss: 3.6431, accuracy: 0.1480\n",
      "--------------------------------------------------\n",
      "Epoch: 2\n",
      "Train loss: 3.6472, accuracy: 0.1444\n",
      "Test loss: 3.4635, accuracy: 0.1847\n",
      "--------------------------------------------------\n",
      "Epoch: 3\n",
      "Train loss: 3.4926, accuracy: 0.1686\n",
      "Test loss: 3.2005, accuracy: 0.2215\n",
      "--------------------------------------------------\n",
      "Epoch: 4\n",
      "Train loss: 3.3860, accuracy: 0.1899\n",
      "Test loss: 3.1909, accuracy: 0.2240\n",
      "--------------------------------------------------\n",
      "Epoch: 5\n",
      "Train loss: 3.3073, accuracy: 0.2036\n",
      "Test loss: 3.1775, accuracy: 0.2362\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 32, 3, 1, 1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(32),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Conv2d(32, 64, 3, 1, 1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm2d(64),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(4096, 1024),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(1024, 100),\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(\"-\" * 20, \" Training \", \"-\" * 20)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_acc  = 0\n",
    "    for batch, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "    train_loss /= batch + 1\n",
    "    train_acc  /= trainloader.batch_size * (batch + 1)\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        accuracy  = 0\n",
    "        for batch, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            y_pred = model(images)\n",
    "            loss = criterion(y_pred, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            accuracy  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "        test_loss /= batch + 1\n",
    "        accuracy  /= testloader.batch_size * (batch + 1)\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}, accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 0us/step\n",
      "x_train shape: torch.Size([50000, 32, 32, 3])\n",
      "y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test  = x_test / 255\n",
    "\n",
    "augment = keras.Sequential([\n",
    "    keras.layers.RandomRotation(0.2),\n",
    "    keras.layers.RandomZoom(0.2),\n",
    "    keras.layers.RandomFlip(),\n",
    "])\n",
    "\n",
    "x_train = augment(x_train)\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  Training  --------------------\n",
      "Epoch 1/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - loss: 4.4709 - sparse_categorical_accuracy: 0.0628 - val_loss: 3.6481 - val_sparse_categorical_accuracy: 0.1408\n",
      "Epoch 2/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 3.6720 - sparse_categorical_accuracy: 0.1335 - val_loss: 3.4498 - val_sparse_categorical_accuracy: 0.1737\n",
      "Epoch 3/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - loss: 3.4684 - sparse_categorical_accuracy: 0.1730 - val_loss: 3.4240 - val_sparse_categorical_accuracy: 0.1861\n",
      "Epoch 4/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - loss: 3.3006 - sparse_categorical_accuracy: 0.2005 - val_loss: 3.2106 - val_sparse_categorical_accuracy: 0.2227\n",
      "Epoch 5/5\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - loss: 3.1793 - sparse_categorical_accuracy: 0.2210 - val_loss: 3.1118 - val_sparse_categorical_accuracy: 0.2357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ff6cffa1850>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=(32, 32, 3)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(100, activation='softmax'))\n",
    "\n",
    "print(\"-\" * 20, \" Training \", \"-\" * 20)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy()\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    epochs=5,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 Transfet Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train size: 50000\n",
      "Test size: 10000\n",
      "Image shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (1.0, 1.0, 1.0)),\n",
    "])\n",
    "\n",
    "\n",
    "target_transform = transforms.Lambda(lambda x: torch.nn.functional.one_hot(torch.tensor(x).long(), num_classes=100).float())\n",
    "\n",
    "train = datasets.CIFAR100(\n",
    "    \"cifar100\",\n",
    "    train=True,\n",
    "    transform=train_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test  = datasets.CIFAR100(\n",
    "    \"cifar100\",\n",
    "    train=False,\n",
    "    transform=test_transform,\n",
    "    target_transform=target_transform,\n",
    "    download=True\n",
    ")\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=128,  shuffle=True)\n",
    "testloader  = torch.utils.data.DataLoader(test,  batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train)}\")\n",
    "print(f\"Test size: {len(test)}\")\n",
    "\n",
    "print(f\"Image shape: {train[0][0].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------  ResNet50  --------------------\n",
      "--------------------  Training  --------------------\n",
      "Epoch: 1\n",
      "Train loss: 3.2599, accuracy: 0.2500\n",
      "Test loss: 2.5970, accuracy: 0.3580\n",
      "--------------------------------------------------\n",
      "Epoch: 2\n",
      "Train loss: 2.5003, accuracy: 0.3703\n",
      "Test loss: 2.2858, accuracy: 0.4137\n",
      "--------------------------------------------------\n",
      "Epoch: 3\n",
      "Train loss: 2.3272, accuracy: 0.3987\n",
      "Test loss: 2.1685, accuracy: 0.4401\n",
      "--------------------------------------------------\n",
      "Epoch: 4\n",
      "Train loss: 2.2492, accuracy: 0.4149\n",
      "Test loss: 2.1331, accuracy: 0.4418\n",
      "--------------------------------------------------\n",
      "Epoch: 5\n",
      "Train loss: 2.2015, accuracy: 0.4221\n",
      "Test loss: 2.0690, accuracy: 0.4564\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"-\" * 20, \" ResNet50 \", \"-\" * 20)\n",
    "print(\"-\" * 20, \" Training \", \"-\" * 20)\n",
    "\n",
    "resnet.fc = torch.nn.Linear(512, 100)\n",
    "\n",
    "resnet.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(resnet.fc.parameters(), lr=0.001, betas=(0.9, 0.9))\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    resnet.train()\n",
    "    train_loss = 0\n",
    "    train_acc  = 0\n",
    "    for batch, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        y_pred = resnet(images)\n",
    "        loss = criterion(y_pred, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "    train_loss /= batch + 1\n",
    "    train_acc  /= trainloader.batch_size * (batch + 1)\n",
    "\n",
    "    resnet.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0\n",
    "        accuracy  = 0\n",
    "        for batch, (images, labels) in enumerate(testloader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            y_pred = resnet(images)\n",
    "            loss = criterion(y_pred, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            accuracy  += (y_pred.argmax(dim=1) == labels.argmax(dim=1)).sum().item()\n",
    "\n",
    "        test_loss /= batch + 1\n",
    "        accuracy  /= testloader.batch_size * (batch + 1)\n",
    "    \n",
    "    print(f\"Epoch: {epoch + 1}\")\n",
    "    print(f\"Train loss: {train_loss:.4f}, accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test loss: {test_loss:.4f}, accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
